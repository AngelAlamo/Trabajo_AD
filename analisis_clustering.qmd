---
title: "Análisis con clustering"
format: html
editor: visual
author: 
  - name: Ángel Álamo
  - name: Juanjo Doblas
  - name: Óscar Vanrell 
execute:
  echo: false
---

En este documento vamos a realizar un análisis con Clustering de las variables cuantitativas de nuestro dataset Spotify 2023. Consideraremos dos submuestras: las 50 canciones más escuchadas, y así poder ver si los métodos de clustering agrupan las cacnciones según su género musical; los 5 artistas más escuchados, para comprobar si los métodos agrupan las canciones según el artista.

Primero, cargamos las librerías que utilizaremos y nuestro dataset.

```{r librerias, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library("factoextra")
library("ggfortify")
library(cluster)
```

```{r dataset, warning=FALSE}
spotify = read_csv(file = "spotify-2023.csv", show_col_types = FALSE)

breaks_bpm = c("60", "100", "120", "210")

# Cambiamos el tipo de los valores
spotify2 <- spotify %>% 
  mutate(streams = as.numeric(streams),
         released_month = as.ordered(released_month),
         released_day = as.ordered(released_day),
         key = factor(key, levels = c("C", "C#", "D", "D#", "E", "F", "G", "G#", "A", "A#", "B"))) %>%
  mutate(across(where(is.character), as.factor)) %>% # chr a factor
  mutate(artist_count = as.factor(artist_count)) %>% 
  
  # Creamos la variable colaboración
  mutate("collaboration" = case_when(
    artist_count == 1 ~ "solo",
    artist_count %in% 2:10 ~ "collaboration", 
    NA ~ NA)) %>%
  
  # Creamos y añadimos la variable reproducciones por artista y la posicionamos antes de el dia de lanzamiento
  group_by(`artist(s)_name`) %>%
  #mutate("songs_per_artist" = n()) %>% 
  mutate("artist_streams" = sum(streams)) %>%
  ungroup() %>%
  #relocate(songs_per_artist, .before = released_year )
  
  # Creamos las variables "rango_bpm" ; "tempo"
  mutate(rango_bpm = cut(bpm, breaks = breaks_bpm, include.lowest = TRUE),
         tempo = factor(case_when(
           between(bpm, 60, 100) ~ "Lenta",
           between(bpm, 101, 120) ~ "Normal",
           between(bpm, 121, 210) ~ "Rápida"
         ))) %>% 
  relocate(rango_bpm, .before = key) %>% 
  relocate(tempo, .after = rango_bpm) %>% 
  
  # Renombramos variables
  dplyr::rename("dance%" = `danceability_%`,
         "valence%" = `valence_%`,
        "energy%" = `energy_%`,
         "acoustic%" = `acousticness_%`,
         "instrumental%" = `instrumentalness_%`,
         "live%" = `liveness_%`,
         "speech%" = `speechiness_%`,
         artist = `artist(s)_name`) %>% 
  
  # Creamos la variable epoca
  mutate(epoca = case_when(
  between(released_year, 1930, 1999) ~ "Epoca_1",
  between(released_year, 2000, 2015) ~ "Epoca_2",
  between(released_year, 2016, 2021) ~ "Epoca_3",
  between(released_year, 2022, 2023) ~ "Epoca_4",
  )) %>% 
  relocate(epoca, .after = released_year) %>% 
  mutate(epoca = ordered(epoca, labels = c("Epoca_1", "Epoca_2", "Epoca_3", "Epoca_4"))) %>% 
  
  # Añadimos la variable estación de lanzamiento
  mutate("released_season" = case_when(
    released_month %in% c(12, 1, 2) ~ "winter",
    released_month %in% 3:5 ~ "spring",
    released_month %in% 6:8 ~ "summer",
    released_month %in% 9:11 ~ "autumn",
    NA ~ NA)) %>% 
  
  # Necesario para definir la variable época
  mutate(released_year = as.ordered(released_year)) %>% 

  # Eliminamos ciertas variables
  dplyr::select(!contains("charts")) %>% 
  
  # Recolocamos las variables
  relocate(streams, .after = artist_count) %>% 
  relocate(released_day, .before = released_year) %>% 
  relocate(released_month, .before = released_year) %>% 
  relocate(artist, .before = track_name) %>%
  relocate(released_season, .before = released_year) %>%
  relocate(artist_streams, .before = released_day) %>%
  relocate(collaboration, .before = streams)

# Orden personalizado de las estaciones del año
orden_estaciones <- c("spring", "summer", "autumn", "winter")

# Cambia el orden de las estaciones del año
spotify2$released_season <- factor(spotify2$released_season,
                                   levels = orden_estaciones)
```

Los análisis de clustering se dividirán en tres partes, según el método aplicado. Se utilizarán los siguientes métodos aprendidos en clase: el método *k-means*, el método *k-medoids* y el método de clustering jerárquico aglomerativo, donde lo aplicaremos también tres veces considerando distintas distancias entre clusters: enlace completo, enlace medio y Ward.

El motivo del reducir el número de canciones y realizar los dos estudios comentados anteriormente es la gran cantidad de observaciones que tenemos, ya que al representar estos datos, no se puede observar con claridad los resultados del clustering.

## Top 50

En este apartado haremos el estudio de clustering de nuestros datos tomando las 50 canciones más escuchadas hasta verano de 2023 en Spotify. Como hemos comentado antes, el objetivo es ver si se agrupan según el género musical de la canción.

Tomamos los datos de las 50 canciones más escuchadas y después (con ayuda de internet) creamos una nueva variable que nos da el género musical de estas 50 canciones:

```{r top 50 canciones con genero, warning=FALSE}
top50canciones <- spotify2 %>% 
  slice_max(streams, n = 50)

genero <- c("pop", "dancehall", "pop", "electronic", "hip-hop", "dancehall",
            "pop", "popRock", "electronic", "pop", "pop", "popRock", "pop", "pop",
            "pop", "pop", "pop", "dancehall", "hip-hop", "popRock", "pop", "pop",
            "electronic", "rock", "popRock", "popRock", "dancehall", "pop", "pop",
            "popRock", "pop", "dancehall", "hip-hop", "hip-hop", "hip-hop",
            "dancehall", "popRock", "pop", "popRock", "hip-hop", "hip-hop", "pop",
            "rock", "dancehall", "hip-hop", "rock", "dancehall", "popRock",
            "rock", "hip-hop")

top50canciones <- top50canciones %>%
  add_column(genero = genero) %>%
  relocate(genero, .after = track_name) %>%
  glimpse
```

-   *genero*: variable cualitativa que muestra el género musical de la canción.

Tenemos 6 posibles valores en la variable *género*:

-   Pop

-   Dancehall: incluye las canciones pop/dance y hemos añadido la única que pertenece al género reggaeton/trap

-   PopRock

-   Rock

-   Electronic

-   Hip-hop

### Representación en el plano principal

Primero, representaremos estas 50 canciones en el plano formado por las dos primeras componentes principales con el objetivo de ver inicialmente la distribución de estas canciones. Esta representación se hará únicamente con las variables porcentuales, por dos razones: estas variables están en la misma unidad de medida y queremos tener en cuenta la variabilidad presente, por lo tanto considerando solo las porcentuales no es necesario tipificar (únicamente centrar); y, por otra parte, al ser estas observaciones las canciones más escuchadas, tiene más sentido representarlas según las propiedades de estas.

```{r var porcentajes top50, warning=FALSE}
spotify_perc50 <- top50canciones %>% 
  select(contains("%")) %>% 
  na.omit()

spotify_perc50 %>%
  mutate(track_name = top50canciones$track_name, genero = top50canciones$genero) %>% 
  relocate(track_name, .before = `dance%`) %>% 
  relocate(genero, .before = `dance%`) %>% 
  glimpse
```

Ahora, centraremos estos datos y obtenemos lo siguiente:

```{r top50 var porcentaje centrados, warning=FALSE}
# Número de filas
m = nrow(spotify_perc50)

# Matriz de centrado
Hm = diag(m) - 1/m

# Datos centrados
sp_perc_cen50 = as_tibble(Hm %*% as.matrix(spotify_perc50))

sp_perc_cen50 <- sp_perc_cen50 %>% 
  add_column(genero = genero, track_name = top50canciones$track_name) %>%
  relocate(genero, .before = `dance%`) %>%
  relocate(track_name, .before = genero) %>%
  glimpse

```


```{r acp top50}
sp_perc_cen_acp50 = prcomp(sp_perc_cen50[,3:9], scale = FALSE)
```

Veamos la representación de los puntos en el plano:


```{r representacion}
fviz_pca_ind(sp_perc_cen_acp50, col.ind = sp_perc_cen50$genero, repel = TRUE,
             label = FALSE, title = "Representación de las top50 canciones con ACP",
             subtitle = "Variables porcentuales", legend.title = "Géneros musicales") + 
  theme_bw() +
  theme(plot.title = element_text(size = 15),
        plot.subtitle = element_text(size = 12))

# Por que me salen figuritas, solo quiero puntos de colores :(
```

Pasemos ahora a realizar las tres técnicas aprendidas en clase: el método *k-means*, el método *k-medoids* y el método de clustering jerárquico aglomerativo, con los siguientes métodos de distancias entre clusters: enlace completo, enlace medio y Ward.

### Método k-means

Para el método de *k-means* hay que elegir previamente el número de clusters que deseamos. En nuestro caso, como el objetivo es agrupar por género, decidimos que el número de clusters sea 6. Los centros dejaremos que se seleccionen de manera aleatoria. Utilizando la función de R `kmeans`, obtenemos los siguientes resultados:

```{r}
set.seed(123)

km_clusters <- kmeans(x = sp_perc_cen50[,3:9], centers = 6, nstart = 25)
km_clusters
```

En la primera línea tenemos los tamaños de los clusters: $7, 8, 8, 9, 11, 7$, y como vemos, más o menos los grupos están equilibrados y no hay ninguno con pocas observaciones, esto es bueno ya que esto nos podría indicar que no hay presencia de valores atípicos (outliers). Por otro lado, el porcentaje de variabilidad que explican los clusters es $70.3\%$. A continuación mostramos los grupos formados por el método *k-means* a partir de las dos primeras componentes principales:

```{r}
fviz_cluster(object = km_clusters, data = sp_perc_cen50[,3:9], show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE,
             main = "Representación con CP", subtitle = "Método k-means, k = 6") + 
  theme_bw() +
  theme(legend.position = "none") +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15))

```


```{r tabla mean, warning = FALSE}

tabla_mean = as_tibble(cbind(km_clusters$cluster, genero)) %>% 
  rename("Cluster" = "V1") %>% 
  table()

tabla_mean
```



### Método k-medoids

De la misma manera que en el método *k-means*, consideraremos $k = 6$ clusters. Si utilizamos la función ` pam ` de R, obtenemos los siguientes medoides:


```{r repr_medoid_6}


spotify_pam_6 <- pam(x = spotify_perc50, k = 6, metric = "euclidean", nstart = 50)

spotify_pam_6$medoids

```

que corresponden a las observaciones `r spotify_pam_6$id.med` respectivamente. Si vemos los grupos formados en el plano a partir de las componentes principales:



```{r repr_medoids_6}

id_medoids6 = c(30, 9, 3, 41, 25, 49)

# Para resaltar los medoides
medoids6 <- prcomp(spotify_perc50, scale = TRUE)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids

medoids6 <- medoids6[id_medoids6, c("PC1", "PC2")]


medoids6 <- as.data.frame(medoids6)

# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids6) <- c("x", "y")


fviz_cluster(object = spotify_pam_6, data = spotify_perc_50, ellipse.type = "t", repel = TRUE,
             main = "Representación con ACP", subtitle = "Método k-medoids, k = 6") +
  theme_bw() +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  
  #Medoides 
  geom_point(data = medoids6, color = "#683068", size = 2.5)
```

Debido a que con dos componentes principales la cantidad de varianza que explican es baja (aproximadamente un $50\%$), esta representación no es del todo precisa. Como vemos, los grupos que se forman se interesectan y no parece haber una distinción clara de los grupos. Por último, mostramos la tabla de frecuencias de los clusters respecto el género musical:


```{r tabla medoid}

tabla_medoids = as_tibble(cbind(spotify_pam_6$clustering, genero)) %>% 
  rename("Cluster" = "V1") %>% 
  table()

tabla_medoids
```


En general, ningún género musical pertenece a un único cluster, por lo tanto la agrupación obtenida a partir del método *k-medoids* no es del todo buena. Además, en cada cluster pertenecen al menos dos observaciones con distinto género musical, y en el mejor caso, corresponde al cluster 3 que contiene a la mayor cantidad de canciones pop, y 2 canciones popRock. 


### Método de clustering jerárquico aglomerativo


Utilizaremos este método con tres tipos de distancia: medio, completa y Ward. Todos ellos utilizarán como matriz de distancia la obtenida aplicando la distancia euclidea:

#### Enlace medio

```{r enlace_media_50}

mat_dist50 = dist(x = spotify_perc50, method = "euclidean")

# Dendograma
dend_media_50 = hclust(d = mat_dist50, method = "average")


```

```{r dend_media50, warning=FALSE}

fviz_dend(x = dend_media_50, k = 6, cex = 0.6)

```

A partir del dendograma podemos ver el proceso de construcción de estos grupos, donde hemos considerado $k = 6$ clusters. Como podemos observar, hay un cluster formado por un único elemento, la observación 28 y otro cluster con tres elementos: 40, 6 y 35. Podemos comprobar si este dendograma realmente refleja las distancias originales entre observaciones a partir de la correlación: 


```{r cor_media50}
# Para ver si la estructura refleja las distancias originales entre observaciones
cor(x = mat_dist50, cophenetic(dend_media_50))

```

Recordemos que se considera una buena representación si es $> 0.75$. En este caso, hemos obtenido una correlación aproximada de $0.65\%$ lo cual indica que no refleja del todo bien las distancias entre observaciones. Si vemos los grupos en el plano:


```{r plano_media50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_media_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```

Vemos que los grupos 4 y 6 no tienen mucho sentido considerarlos, ya que según la representación podríamos deducir que estas observaciones deberían pertenecer otros grupos y por lo tanto tendríamos 4 grupos principales. Aún así, podemos comprobar si se han agrupado correctamente los géneros:


```{r tabla media}

tabla_media = as_tibble(cbind(cutree(dend_media_50, k = 6), genero)) %>% 
  rename("Cluster" = "V1") %>% 
  table()

tabla_media
```


A partir de este método, se consigue una agrupación completa del género rock, presente en el cluster 5, no obstante, contiene algo de "ruido" ya que también hay observaciones de otros géneros musicales. Respecto al género dancehall, se ha podido agrupar mejor si comparamos con los métodos anteriores, donde ahora la mayoría están contenidos en el cluster 1. Por otro lado, géneros como el pop se han acumulado en dos clusters, el primero y el tercero.


#### Enlace completo


Repetimos el proceso anterior, considerando ahora la distancia completa entre clusters.

```{r enlace_completo_50}

# Dendograma
dend_compl_50 = hclust(d = mat_dist50, method = "complete")

```

```{r dend_compl50}

fviz_dend(x = dend_compl_50, k = 6, cex = 0.6)

```

```{r cor_compl50}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist50, cophenetic(dend_compl_50))

```


A partir de esta distancia, comparando con la anterior, se obtienen grupos más equilibrados, donde ahora hay al menos 6 observaciones en cada grupo. Respecto al coeficiente de correlación entre las distancias, es superior al anterior, donde ahora es aproximadamente un $0.68$. Además, si vemos las agrupaciones en el plano:


```{r plano_compl50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_compl_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```

Tenemos que no hay ningún grupo que se intersecta y todo grupo formado parece tener un sentido considerarlos. Por último, si hacemos la tabla cluster.género:

```{r tabla_completa50}

tabla_completa = as_tibble(cbind(cutree(dend_compl_50, k = 6), genero)) %>% 
  rename("Cluster" = "V1") %>% 
  table()

tabla_completa

```

Aún teniendo una mejor estructura y una mejor respresentación de las distancias, los grupos no reflejan las diferencias entre los géneros y se ha perdido una representación de estos, ya que ahora las observaciones parecen estar más dispersas entre los clusters.


#### Ward


Como última distancia entre clsuters, consideraremos la distancia Ward. 

```{r enlace_ward_50}

# Dendograma
dend_ward_50 = hclust(d = mat_dist50, method = "ward.D2")

```

```{r dend_ward}

fviz_dend(x = dend_ward_50, k = 6, cex = 0.6)

```

```{r cor_ward50}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist50, cophenetic(dend_ward_50))

```

Nuevamente, obtenemos una agrupación interesante de los datos, aunque respecto al anterior, el coeficiente de correlación es algo inferior, por lo que puede indicar que esta representación no respeta correctamente la distancia real entre las observaciones. Si vemos estos clusters en el plano:

```{r plano_ward50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_ward_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```

En general, tenemos grupos coherentes y muy similares a los anteriores, excepto el grupo 1, que no parece encajar de todo en la estructura formada, esto podría indicar que el número de clusters que se debería indicar es realmente $k = 5$, de manera que este grupo se repartiría entre los grupos 4,5 y 6 haciendo una estructura más solida y mejor representada. Si vemos la tabla cluster-género:


```{r tabla_ward}

tabla_ward = as_tibble(cbind(cutree(dend_ward_50, k = 6), genero)) %>% 
  rename("Cluster" = "V1") %>% 
  table()

tabla_ward

```

En este caso, hemos perdido una agrupación de los géneros dancehall y rock, en cambio, el género pop se ha agrupado principalmente en el cluster 3. Respecto a los otros géneros, seguimos obteniendo la misma dispersión entre clusters






## Top5 artistas

Vamos a realizar el mismo estudio ahora considerando otros datos y agrupaciones. En el trabajo anterior estudiamos cuales eran los 5 artistas con más reproducciones en Spotify y las características de sus canciones asi que nos parece interesante estudiar si tomando los datos de estas canciones y sus características encontraremos una agrupación en cuanto al artista que las compone.

Por lo tanto, consideramos los datos de los 5 artistas con más reproducciones: Taylor Swift, The Weeknd, Bad Bunny, SZA y Harry Styles

```{r dataset_top3, warning= FALSE}

# Dataset completo con solo los artistas top 5
spotify_top5 = spotify2 %>% 
  filter(artist %in% c("Taylor Swift", "The Weeknd", "Bad Bunny", "SZA", "Harry Styles")) %>% 
  mutate(artist = as.character(artist)) %>%
  mutate(artist = as.factor(artist)) %>% 
  arrange(artist)
  
spotify_top5 %>% 
  glimpse


# Dataset Artistas top5
#spotify_top5_artists = spotify_top5 %>% 
  #group_by(artist) %>% 
  #summarise()

```

Otra vez solo consideramos las variables cuantitativas porcentuales que representan las características de cada canción:

```{r}
spotify_perc5 = spotify_top5 %>% 
  select(contains("%"))

spotify_perc5%>%
  glimpse
```

### Representación en el plano principal

```{r top5 var porcentaje centrados, warning=FALSE}
# Número de filas
n = nrow(spotify_perc5)

# Matriz de centrado
Hn = diag(n) - 1/n

# Datos centrados
sp_perc_cen5 = as_tibble(Hn %*% as.matrix(spotify_perc5))

sp_perc_cen5 <- sp_perc_cen5 %>% 
  add_column(artist = spotify_top5$artist, track_name = spotify_top5$track_name) %>%
  relocate(track_name, .before = `dance%`) %>%
  relocate(artist, .before = track_name) %>%
  glimpse
```

Calculamos las componentes principales con la función `prcomp`:

```{r acp top5}
sp_perc_cen_acp5 = prcomp(sp_perc_cen5[,3:9], scale = FALSE)
```

Veamos la representación de los puntos en el plano:

```{r representacion top5}
fviz_pca_ind(sp_perc_cen_acp5, col.ind = sp_perc_cen5$artist, repel = TRUE,
             label = FALSE, title = "Gráfico de los top5 artistas con ACP",
             subtitle = "Variables porcentuales") + 
  theme_bw() +
  theme(plot.title = element_text(size = 15),
        plot.subtitle = element_text(size = 12))

# Por que me salen figuritas, solo quiero puntos de colores :(
```

Empecemos el estudio del clustering con los diferentes métodos que conocemos:

### Método k-means.

```{r}
#datos <- scale(spotify_perc50)
```

```{r}
set.seed(12400)
km_clusters1 <- kmeans(x = spotify_perc5, centers = 5, nstart = 25)
km_clusters1
```

```{r}
fviz_cluster(object = km_clusters1, data = spotify_perc5, show.clust.cent = TRUE,
 ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
theme_bw() +
theme(legend.position = "none")
```

### Método k-medoids.


```{r}


spotify_pam5 <- pam(x = spotify_perc5, k = 5, metric = "euclidean")

spotify_pam5$id.med
```



```{r}
id_medoids5 = c(96,58,8,16,36)

spotify_perc5 %>% 
  filter(rownames(.) %in% id_medoids5) %>%
  mutate(id5 = id_medoids5) %>% 
  relocate(id5, .before = "dance%") %>% 
  show()

```

Veamos las agrupaciones en el plano a partir de las componentes principales, solo considerando dos dimensiones.

```{r}
# Para resaltar los medoides
medoids5 <- prcomp(spotify_perc5, scale = TRUE)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids

medoids5 <- medoids5[id_medoids5, c("PC1", "PC2")]


medoids5 <- as.data.frame(medoids5)
# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids5) <- c("x", "y")


fviz_cluster(object = spotify_pam5, data = spotify_perc_5, ellipse.type = "t", repel = TRUE) +
  theme_bw() +
  labs(title = "Representación con Componentes Principales") +
  theme(legend.position = "none") +
  
  #Medoides 
  geom_point(data = medoids5, color = "#EE0606", size = 2)

```





### Método de clustering jerárquico aglomerativo.




#### Enlace completo:

```{r}

mat_dist5 = dist(x = spotify_perc5, method = "euclidean")

# Dendograma
dend_complete_5 = hclust(d = mat_dist5, method = "complete")

```

```{r}

fviz_dend(x = dend_complete_5, k = 5, cex = 0.6)

```



```{r}
# Para ver si la estructura refleja las distancias originales entre observaciones
cor(x = mat_dist5, cophenetic(dend_complete_5))

```


```{r}

fviz_cluster(object = list(data = spotify_perc5, cluster = cutree(dend_complete_5, k = 5)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```

#### Enlace medio

Repetimos el proceso anterior, considerando ahora la distancia media entre clusters.

```{r}

# Dendograma
dend_med_5 = hclust(d = mat_dist5, method = "average")

```

```{r}

fviz_dend(x = dend_med_5, k = 5, cex = 0.6)

```

```{r}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist5, cophenetic(dend_med_5))

```

Tenemos dos agrupaciones principales y pese a ello el coeficiente de correlación entre las distancias es superior a la anterior, de aproximadamente $0.72$, por lo tanto esta estructura deberia reflejar las distancias originales entre las observaciones. Por último, veamos las agrupaciones en el plano:

```{r}

fviz_cluster(object = list(data = spotify_perc5, cluster = cutree(dend_med_5, k = 5)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```


#### Ward

Como última distancia entre clsuters, consideraremos la distancia Ward.

```{r}

# Dendograma
dend_ward_5 = hclust(d = mat_dist5, method = "ward.D2")

```

```{r}

fviz_dend(x = dend_ward_5, k = 5, cex = 0.6)

```

```{r}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist5, cophenetic(dend_ward_5))

```

Finalmente, obtenemos una agrupación donde el coeficiente de correlación es bastante inferior, por lo que puede indicar que esta representación no respeta correctamente la distancia real entre las observaciones. Si vemos estos clusters en el plano:

```{r}

fviz_cluster(object = list(data = spotify_perc5, cluster = cutree(dend_ward_5, k = 5)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```










