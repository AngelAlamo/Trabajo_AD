---
title: "Análisis con clustering"
format: html
editor: visual
author: 
  - name: Ángel Álamo
  - name: Juanjo Doblas
  - name: Óscar Vanrell 
execute:
  echo: false
---

En este documento vamos a realizar un análisis con Clustering de las variables cuantitativas de nuestro dataset Spotify 2023. Consideraremos dos submuestras: las 50 canciones más escuchadas, y así poder ver si los métodos de clustering agrupan las cacnciones según su género musical; los 5 artistas más escuchados, para comprobar si los métodos agrupan las canciones según el artista.

Primero, cargamos las librerías que utilizaremos y nuestro dataset.

```{r librerias, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library("factoextra")
library("ggfortify")
library(cluster)
```

```{r dataset var cuant, warning=FALSE}
spotify = read_csv(file = "spotify-2023.csv", show_col_types = FALSE)

breaks_bpm = c("60", "100", "120", "210")

# Cambiamos el tipo de los valores
spotify2 <- spotify %>% 
  mutate(streams = as.numeric(streams),
         released_month = as.ordered(released_month),
         released_day = as.ordered(released_day),
         key = factor(key, levels = c("C", "C#", "D", "D#", "E", "F", "G", "G#", "A", "A#", "B"))) %>%
  mutate(across(where(is.character), as.factor)) %>% # chr a factor
  mutate(artist_count = as.factor(artist_count)) %>% 
  
  # Creamos la variable colaboración
  mutate("collaboration" = case_when(
    artist_count == 1 ~ "solo",
    artist_count %in% 2:10 ~ "collaboration", 
    NA ~ NA)) %>%
  
  # Creamos y añadimos la variable reproducciones por artista y la posicionamos antes de el dia de lanzamiento
  group_by(`artist(s)_name`) %>%
  #mutate("songs_per_artist" = n()) %>% 
  mutate("artist_streams" = sum(streams)) %>%
  ungroup() %>%
  #relocate(songs_per_artist, .before = released_year )
  
  # Creamos las variables "rango_bpm" ; "tempo"
  mutate(rango_bpm = cut(bpm, breaks = breaks_bpm, include.lowest = TRUE),
         tempo = factor(case_when(
           between(bpm, 60, 100) ~ "Lenta",
           between(bpm, 101, 120) ~ "Normal",
           between(bpm, 121, 210) ~ "Rápida"
         ))) %>% 
  relocate(rango_bpm, .before = key) %>% 
  relocate(tempo, .after = rango_bpm) %>% 
  
  # Renombramos variables
  dplyr::rename("dance%" = `danceability_%`,
         "valence%" = `valence_%`,
        "energy%" = `energy_%`,
         "acoustic%" = `acousticness_%`,
         "instrumental%" = `instrumentalness_%`,
         "live%" = `liveness_%`,
         "speech%" = `speechiness_%`,
         artist = `artist(s)_name`) %>% 
  
  # Creamos la variable epoca
  mutate(epoca = case_when(
  between(released_year, 1930, 1999) ~ "Epoca_1",
  between(released_year, 2000, 2015) ~ "Epoca_2",
  between(released_year, 2016, 2021) ~ "Epoca_3",
  between(released_year, 2022, 2023) ~ "Epoca_4",
  )) %>% 
  relocate(epoca, .after = released_year) %>% 
  mutate(epoca = ordered(epoca, labels = c("Epoca_1", "Epoca_2", "Epoca_3", "Epoca_4"))) %>% 
  
  # Añadimos la variable estación de lanzamiento
  mutate("released_season" = case_when(
    released_month %in% c(12, 1, 2) ~ "winter",
    released_month %in% 3:5 ~ "spring",
    released_month %in% 6:8 ~ "summer",
    released_month %in% 9:11 ~ "autumn",
    NA ~ NA)) %>% 
  
  # Necesario para definir la variable época
  mutate(released_year = as.ordered(released_year)) %>% 

  # Eliminamos ciertas variables
  dplyr::select(!contains("charts")) %>% 
  
  # Recolocamos las variables
  relocate(streams, .after = artist_count) %>% 
  relocate(released_day, .before = released_year) %>% 
  relocate(released_month, .before = released_year) %>% 
  relocate(artist, .before = track_name) %>%
  relocate(released_season, .before = released_year) %>%
  relocate(artist_streams, .before = released_day) %>%
  relocate(collaboration, .before = streams)

# Orden personalizado de las estaciones del año
orden_estaciones <- c("spring", "summer", "autumn", "winter")

# Cambia el orden de las estaciones del año
spotify2$released_season <- factor(spotify2$released_season,
                                   levels = orden_estaciones)
```

Los análisis de clustering se dividirán en tres partes, según el método aplicado. Se utilizarán los siguientes métodos aprendidos en clase: el método *k-means*, el método *k-medoids* y el método de clustering jerárquico aglomerativo, donde lo aplicaremos también tres veces considerando distintas distancias entre clusters: enlace completo, enlace medio y Ward.

El motivo del reducir el número de canciones y realizar los dos estudios comentados anteriormente es la gran cantidad de observaciones que tenemos, ya que al representar estos datos, no se puede observar con claridad los resultados del clustering.


## Top 50

En este apartado haremos el estudio de clustering de nuestros datos tomando las 50 canciones más escuchadas hasta verano de 2023 en Spotify. Como hemos comentado antes, el objetivo es ver si se agrupan según el género musical de la canción.

Tomamos los datos de las 50 canciones más escuchadas y después (con ayuda de internet) creamos una nueva variable que nos da el género musical de estas 50 canciones:

```{r top 50 canciones con genero, warning=FALSE}
top50canciones <- spotify2 %>% 
  slice_max(streams, n = 50)

genero <- c("pop", "dancehall", "pop", "electronic", "hip-hop", "dancehall",
            "pop", "popRock", "electronic", "pop", "pop", "popRock", "pop", "pop",
            "pop", "pop", "pop", "dancehall", "hip-hop", "popRock", "pop", "pop",
            "electronic", "rock", "popRock", "popRock", "dancehall", "pop", "pop",
            "popRock", "pop", "dancehall", "hip-hop", "hip-hop", "hip-hop",
            "dancehall", "popRock", "pop", "popRock", "hip-hop", "hip-hop", "pop",
            "rock", "dancehall", "hip-hop", "rock", "dancehall", "popRock",
            "rock", "hip-hop")

top50canciones <- top50canciones %>%
  add_column(genero = genero) %>%
  relocate(genero, .after = track_name) %>%
  glimpse
```


-   *genero*: variable cualitativa que muestra el género musical de la canción.


Tenemos 6 posibles valores en la variable *género*:

- Pop

- Dancehall: incluye las canciones pop/dance y hemos añadido la única que pertenece al género reggaeton/trap

- PopRock

- Rock

- Electronic

- Hip-hop


### Representación en el plano principal

Primero, representaremos estas 50 canciones en el plano formado por las dos primeras componentes principales con el objetivo de ver inicialmente la distribución de estas canciones. Esta representación se hará únicamente con las variables porcentuales, por dos razones: estas variables están en la misma unidad de medida y queremos tener en cuenta la variabilidad presente, por lo tanto considerando solo las porcentuales no es necesario tipificar (únicamente centrar); y, por otra parte, al ser estas observaciones las canciones más escuchadas, tiene más sentido representarlas según las propiedades de estas.

```{r var porcentajes top50, warning=FALSE}
spotify_perc50 <- top50canciones %>% 
  select(contains("%")) %>% 
  na.omit()

spotify_perc50 %>%
  mutate(track_name = top50canciones$track_name) %>% 
  relocate(track_name, .before = `dance%`) %>% 
  glimpse
```

Ahora, centraremos estos datos y obtenemos lo siguiente:


```{r top50 var porcentaje centrados, warning=FALSE}
# Número de filas
m = nrow(spotify_perc50)

# Matriz de centrado
Hm = diag(m) - 1/m

# Datos centrados
sp_perc_cen50 = as_tibble(Hm %*% as.matrix(spotify_perc50))

sp_perc_cen50 <- sp_perc_cen50 %>% 
  add_column(genero = genero, track_name = top50canciones$track_name) %>%
  relocate(genero, .before = `dance%`) %>%
  relocate(track_name, .before = genero) %>%
  glimpse

```

Calculamos las componentes principales con la función ` prcomp`:

```{r acp top50}
sp_perc_cen_acp50 = prcomp(sp_perc_cen50[,3:9], scale = FALSE)
```

Veamos la representación de los puntos en el plano:

```{r representacion}
fviz_pca_ind(sp_perc_cen_acp50, col.ind = sp_perc_cen50$genero, repel = TRUE,
             label = FALSE, title = "Representación de las top50 canciones con ACP",
             subtitle = "Variables porcentuales", legend.title = "Géneros musicales") + 
  theme_bw() +
  theme(plot.title = element_text(size = 15),
        plot.subtitle = element_text(size = 12))

# Por que me salen figuritas, solo quiero puntos de colores :(
```


Pasemos ahora a realizar las tres técnicas aprendidas en clase: el método *k-means*, el método *k-medoids* y el método de clustering jerárquico aglomerativo, con los siguientes métodos de distancias entre clusters: enlace completo, enlace medio y Ward.

### Método k-means

Para el método de *k-means* hay que elegir previamente el número de clusters que deseamos. En nuestro caso, como el objetivo es agrupar por género, decidimos que el número de clusters sea 6. Los centros dejaremos que se seleccionen de manera aleatoria. Utilizando la función de R ` kmeans`, obtenemos los siguientes resultados:

```{r}
set.seed(123)

km_clusters <- kmeans(x = sp_perc_cen50[,3:9], centers = 6, nstart = 25)
km_clusters
```
En la primera línea tenemos los tamaños de los clusters: $7, 8, 8, 9, 11, 7$, y como vemos, más o menos los grupos están equilibrados y no hay ninguno con pocas observaciones, esto es bueno ya que esto nos podría indicar que no hay presencia de valores atípicos (outliers). Por otro lado, el porcentaje de variabilidad  que explican los clusters es $70.3\%$. A continuación mostramos los grupos formados por el método *k-means* a partir de las dos primeras componentes principales:




```{r}
fviz_cluster(object = km_clusters, data = sp_perc_cen50[,3:9], show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE,
             main = "Representación con CP", subtitle = "Método k-means, k = 6") + 
  theme_bw() +
  theme(legend.position = "none") +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15))

```

```{r comentarios 1}
# Faltaría poner una tabla que compare los clusters y el género
```



### Método k-medoids


Recordemos que para aplicar el método *k-medoids*, como en el método *k-means*, se necesitan $k$ puntos de referencia para iniciar el algoritmo. Primero, necesitamos encontrar la $k$ óptima, para esto, utilizaremos la función ` fviz_nbclust()`, con la distancia euclidea y la de Manhattan.


```{r cl_opt_eucl}
# Euclidea
fviz_nbclust(x = spotify_perc50, FUNcluster = pam, method = "wss", diss = dist(spotify_perc50, method = "euclidean")) +
  labs(title = "Número de clusters óptimos", subtitle = "Distancia Euclidea", x = "Número de clusters", y = "Suma total de los cuadrados (wss) ") +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15))
```


```{r cl_optimos_manhattan}
# Manhattan
fviz_nbclust(x = spotify_perc50, FUNcluster = pam, method = "wss", diss = dist(spotify_perc50, method = "manhattan")) +
  labs(title = "Número de clusters óptimos", subtitle = "Distancia Manhattan", x = "Número de clusters", y = "Suma total de los cuadrados (wss) ") +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15))
```

Como podemos ver, con las dos distancias obtenemos el mismo patrón. A partir de estos gráficos podríamos deducir que a partir de $k = 5$ clusters la suma total de los cuadrados internos empieza a estabilizarse, por eso consideraremos este valor de $k$. Para aplicar el método PAM, usaremos la distancia euclidea. Veamos con la función de R, ` pam`, los medoides:


```{r pam_5}

spotify_pam <- pam(x = spotify_perc50, k = 5, metric = "euclidean", nstart = 50)

cbind(spotify_pam$id.med,spotify_pam$medoids)

id_medoids = c(7,9,3,18,24)

```

Como podemos ver, los valores que toman los representantes se diferencian principalmente por la variable "acoustic%", y la variable "energy%", lo que nos indica que, en general, estas observaciones se han distinguido por estas características. Además, fijémonos que las observaciones con "ID = 7" y "ID = 18" se diferencian por las otras variables: "dance%" y "valence".

Veamos las agrupaciones en el plano a partir de las componentes principales, solo considerando dos dimensiones.

```{r repr_medoid_5}
# Para resaltar los medoides
medoids <- prcomp(spotify_perc50, scale = TRUE)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids

medoids <- medoids[id_medoids, c("PC1", "PC2")]


medoids <- as.data.frame(medoids)

# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids) <- c("x", "y")


fviz_cluster(object = spotify_pam, data = spotify_perc_50, ellipse.type = "t", repel = TRUE,
             main = "Representación con ACP", subtitle = "Método k-medoids, k = 5") +
  theme_bw() +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  
  #Medoides 
  geom_point(data = medoids, color = "#683068", size = 2.5)

```

Els espacio que forman los grupos no son muy diferenciados, en el sentido de que intersecan con otros grupos, por lo tanto, podemos deducir que la agrupación no es del todo buena, aunque esto puede ser debido a la poca explicación de la varianza de las componentes principales, que es aproximadamente de un $50\%$.

Si comparamos con el caso en que consideramos $k = 6$ clusters (el "correcto"):


```{r repr_medoid_6}


spotify_pam_6 <- pam(x = spotify_perc50, k = 6, metric = "euclidean", nstart = 50)

spotify_pam_6

```

```{r repr_medoids_6}

id_medoids6 = c(30, 9, 3, 41, 25, 49)

# Para resaltar los medoides
medoids6 <- prcomp(spotify_perc50, scale = TRUE)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids

medoids6 <- medoids6[id_medoids6, c("PC1", "PC2")]


medoids6 <- as.data.frame(medoids6)

# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids6) <- c("x", "y")


fviz_cluster(object = spotify_pam_6, data = spotify_perc_50, ellipse.type = "t", repel = TRUE,
             main = "Representación con ACP", subtitle = "Método k-medoids, k = 6") +
  theme_bw() +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  
  #Medoides 
  geom_point(data = medoids6, color = "#683068", size = 2.5)
```






### Método de clustering jerárquico aglomerativo

Utilizaremos este método con tres tipos de distancia: simple, completa y Ward. Todos ellos utilizarán como matriz de distancia la obtenida aplicando la distanica euclidea:

#### Enlace simple:

```{r enlace_simple_50}

mat_dist50 = dist(x = spotify_perc50, method = "euclidean")

# Dendograma
dend_simple_50 = hclust(d = mat_dist50, method = "single")

```

```{r dend_simple}

fviz_dend(x = dend_simple_50, k = 6, cex = 0.6)

```

Como vemos, los clusters obtenidos (hemos considerado $k = 6$) no son nada descriptivos, tenemos 4 grupos formados por un único elemento, otro grupo formado por dos elementos y un grupo que contiene los elementos restantes, de los cuales no podemos deducir mucho. Podemos comprobar si este dendograma realmente refleja las distancias originales entre observaciones: 


```{r cor_simple50}
# Para ver si la estructura refleja las distancias originales entre observaciones
cor(x = mat_dist50, cophenetic(dend_simple_50))

```

Recordemos que se considera una buena representación si $> 0.75$. En este caso, la representación no es nada buena y tendremos que basarnos en las otras distancias para sacar conclusiones. A continuación mostramos los clusters obtenidos en el plano.

```{r plano_simple50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_simple_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```




#### Enlace completo

Repetimos el proceso anterior, consdierando ahora la distancia completa entre clusters.

```{r enlace_completo_50}

# Dendograma
dend_compl_50 = hclust(d = mat_dist50, method = "complete")

```

```{r dend_compl}

fviz_dend(x = dend_compl_50, k = 6, cex = 0.6)

```

```{r cor_compl50}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist50, cophenetic(dend_compl_50))

```


Comparando con el caso anterior, los grupos que se obtienen son mucho más equilibrados en cuanto a observaciones y tienen un mayor sentido. Además, como cabe esperar, el coeficiente de correlación entre las distancias es muy superior a la anterior, de aproximadamente $0.68\%$, por lo tanto esta estructura si que refleja las distancias originales entre las observaciones. Por último, veamos las agrupaciones en el plano:


```{r plano_compl50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_compl_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```

Con gran diferencia, este método con la distancia completa nos ha proporcionado una agrupación más coherente de las observaciones, donde en general se distinguen según el valor que toman en la primera componente principal.



#### Ward


Como última distancia entre clsuters, consideraremos la distancia Ward. 

```{r enlace_ward_50}

# Dendograma
dend_ward_50 = hclust(d = mat_dist50, method = "ward.D2")

```

```{r dend_ward}

fviz_dend(x = dend_ward_50, k = 6, cex = 0.6)

```

```{r cor_ward50}
print("Coeficiente de correlación entre las distancias cophenetic")
cor(x = mat_dist50, cophenetic(dend_ward_50))

```

Nuevamente, obtenemos una agrupación interesante de los datos, aunque respecto al anterior, el coeficiente de correlación es algo inferior, por lo que puede indicar que esta representación no respeta correctamente la distancia real entre las observaciones. Si vemos estos clusters en el plano:

```{r plano_ward50}

fviz_cluster(object = list(data = spotify_perc50, cluster = cutree(dend_ward_50, k = 6)),
 ellipse.type = "convex",
 repel = TRUE,
 show.clust.cent = FALSE) +
theme_bw()

```
En general, tenemos grupos coherentes y muy similares a los anteriores, excepto el grupo 1, que no parece encajar de todo en la estructura formada, esto podría indicar que el número de clusters que se debería indicar es realmente $k = 5$, de manera que este grupo se repartiría entre los grupos 4,5 y 6 haciendo una estructura más solida y mejor representada.







## Top5 artistas 

Vamos a realizar el mismo estudio ahora considerando otros datos y agrupaciones. En el trabajo anterior estudiamos cuales eran los 5 artistas con más reproducciones en Spotify y las características de sus canciones asi que nos parece interesante estudiar si tomando los datos de estas canciones y sus características encontraremos una agrupación en cuanto al artista que las compone.

Por lo tanto, consideramos los datos de los 5 artistas con más reproducciones: Taylor Swift, The Weeknd, Bad Bunny, SZA y Harry Styles 

```{r dataset_top3, warning= FALSE}

# Dataset completo con solo los artistas top 5
spotify_top5 = spotify2 %>% 
  filter(artist %in% c("Taylor Swift", "The Weeknd", "Bad Bunny", "SZA", "Harry Styles")) %>% 
  mutate(artist = as.character(artist)) %>%
  mutate(artist = as.factor(artist)) %>% 
  arrange(artist)
  
spotify_top5 %>% 
  glimpse


# Dataset Artistas top5
#spotify_top5_artists = spotify_top5 %>% 
  #group_by(artist) %>% 
  #summarise()

```


Otra vez solo consideramos las variables cuantitativas porcentuales que representan las características de cada canción:

```{r}
spotify_perc5 = spotify_top5 %>% 
  select(contains("%"))

spotify_perc5%>%
  glimpse
```

### Representación en el plano principal



```{r top5 var porcentaje centrados, warning=FALSE}
# Número de filas
n = nrow(spotify_perc5)

# Matriz de centrado
Hn = diag(n) - 1/n

# Datos centrados
sp_perc_cen5 = as_tibble(Hn %*% as.matrix(spotify_perc5))

sp_perc_cen5 <- sp_perc_cen5 %>% 
  add_column(artist = spotify_top5$artist, track_name = spotify_top5$track_name) %>%
  relocate(track_name, .before = `dance%`) %>%
  relocate(artist, .before = track_name) %>%
  glimpse
```

Calculamos las componentes principales con la función ` prcomp`:

```{r acp top5}
sp_perc_cen_acp5 = prcomp(sp_perc_cen5[,3:9], scale = FALSE)
```

Veamos la representación de los puntos en el plano:

```{r representacion top5}
fviz_pca_ind(sp_perc_cen_acp5, col.ind = sp_perc_cen5$artist, repel = TRUE,
             label = FALSE, title = "Gráfico de los top5 artistas con ACP",
             subtitle = "Variables porcentuales") + 
  theme_bw() +
  theme(plot.title = element_text(size = 15),
        plot.subtitle = element_text(size = 12))

# Por que me salen figuritas, solo quiero puntos de colores :(
```
















Empecemos el estudio del clustering con los diferentes métodos que conocemos:

### Método k-means.

```{r}
#datos <- scale(spotify_perc50)
```



```{r}
set.seed(12400)
km_clusters1 <- kmeans(x = spotify_perc5, centers = 5, nstart = 25)
km_clusters1
```
```{r}
fviz_cluster(object = km_clusters1, data = spotify_perc5, show.clust.cent = TRUE,
 ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
theme_bw() +
theme(legend.position = "none")
```

### Método k-medoids.

Recordemos que para aplicar el método *k-medoids*, como en el método *k-means*, se necesitan $k$ elementos para iniciar el algoritmo. Nosotros tomaremos $k=5$ que son el número de artistas que participan y de los cuales queremos agrupar los resultados.


 Para aplicar el método PAM, usaremos la distancia euclidea. Veamos con la función de R ` pam` los medoides:


```{r}
set.seed(2218)

spotify_pam5 <- pam(x = spotify_perc5, k = 5, metric = "euclidean")

spotify_pam5$id.med
```

Estos son los id de las observaciones representantes de los grupos, veamos los valores que toman estas observaciones.


```{r}
id_medoids5 = c(96,58,8,16,36)

spotify_perc5 %>% 
  filter(rownames(.) %in% id_medoids5) %>%
  mutate(id5 = id_medoids5) %>% 
  relocate(id5, .before = "dance%") %>% 
  show()

```
Veamos las agrupaciones en el plano a partir de las componentes principales, solo considerando dos dimensiones.

```{r}
# Para resaltar los medoides
medoids5 <- prcomp(spotify_perc5, scale = TRUE)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids

medoids5 <- medoids5[id_medoids5, c("PC1", "PC2")]


medoids5 <- as.data.frame(medoids5)
# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids5) <- c("x", "y")


fviz_cluster(object = spotify_pam5, data = spotify_perc_5, ellipse.type = "t", repel = TRUE) +
  theme_bw() +
  labs(title = "Representación con Componentes Principales") +
  theme(legend.position = "none") +
  
  #Medoides 
  geom_point(data = medoids5, color = "#EE0606", size = 2)

```
